{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701ee33c-5624-45c5-8024-b99e0e9e62d1",
   "metadata": {},
   "source": [
    "<img src=\"./assets/intro_banner.png\" width=\"500\" height=\"auto\" />\n",
    "\n",
    "*Content authors: Pedro Lopes, Milan Kornjača*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d16601-5d8e-485a-b8a6-df977b233bd0",
   "metadata": {},
   "source": [
    "We now continue our journey diving deeper into ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc16ff-cddb-4fc9-964f-57d50da0f481",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Learning Objectives\n",
    "\n",
    "#### By the end of the session, you will be able to:\n",
    "- Describe three approaches to quantum machine learning, and their advantages and disadvantages\n",
    "- Describe the power of reservoir computing methods\n",
    "- Deploy a quantum reservoir computing program, performing the steps:\n",
    "    - Encode data-based problems into parameters of a neutral-atom quantum reservoir\n",
    "    - Harvest quantum reservoir outputs from QuEra’s hardware\n",
    "    - Train a classical neural network on top of quantum-hardware data\n",
    "    - Use the quantum reservoir to make data predictions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d7a196-d161-4d39-a685-d638e6ffe212",
   "metadata": {},
   "source": [
    "## 1. Quantum Machine Learning: Status and perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e8ea6-5e72-49ef-8ff7-94894f6cd802",
   "metadata": {},
   "source": [
    "Machine learning refers to a sub-field of artificial intelligence where data-driven algorithms can perform tasks without explicit instructions. It is natural to consider whether or how quantum computers can be incorporated into such workflows, but why should one care about it? In this section, we will discuss the prospects for quantum computers to bring value to machine learning workflows, as QuEra's teams see it. We will then naturally connect to the main topic of this lecture: an introduction to quantum reservoir computing.\n",
    "\n",
    "Besides mastery over the introductory chapters of this course, and thus over quantum computing, some familiarity with regular machine learning is assumed from the reader in this chapter. If you are finding it difficult to follow the discussions and concepts below, we recommend browsing to through the first couple lessons on [this](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187) resource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c5775-0238-4c73-90b0-7ce711b9d743",
   "metadata": {},
   "source": [
    "### 1a. Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94707151-1759-48e2-b132-f81e6c057e0a",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" src=\"./assets/Fig1v2.png\"  width=\"300\" height=\"auto\" />\n",
    "\n",
    "There are several ways of classifying how quantum computing and machine learning methods intersect. Following [Nat. Comput. Sci. 2, 567 (2022)], we can start with the quad-chart to the right: one axis represents types of algorithms (classical or quantum) while the other the type of data (again, classical or quantum). Here, quantum data may be interpreted as data encoded in a quantum state $| \\psi \\rangle$, or more generally as data generated out of quantum tasks, and carrying memory of the rules and correlations of quantum mechanics.\n",
    "\n",
    "In our case, we want to put quantum computers to the test. We are seeking perspectives which would justify the use of quantum computers for quantum machine learning tasks. So we will be concerned only with the bottom row of the quad-chart: can quantum computers be used to process either classical and quantum data, in any context, via machine learning tasks better (faster, more precisely, with less resources) than classical computers?\n",
    "\n",
    "One important disclaimer we should start with: while quantum computers enable algorithmic shortcuts classically hard problems, the difficulty of loading and measuring data, and the overhead incurred by error correction limits their performance for performing arithmetic operations. This is true for current hardware, and remains true in our horizon of understanding of quantum computing value. Thus, while much of classical machine learning is devoted to big-data, odds are that quantum computers will bring more value to situations where data is more limited, either because it is expensive, or simply not available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946bd89-cf0b-4ac0-85d8-83a6647fcb48",
   "metadata": {},
   "source": [
    "### 1b. Provable quantum performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31349b22",
   "metadata": {},
   "source": [
    "As with classical algorithms, some quantum algorithms have provable performance bounds. An example is Schor's algorithms for integer factorization, bounded to achieve the factorization of an integer into primes with exponentially fewer manipulations than any known classical algorithm would for any given fixed integer.\n",
    "\n",
    "<img style=\"float: left;\" src=\"./assets/QML_exact_speedups.png\"  width=\"300\" height=\"auto\" />\n",
    "\n",
    "In the context of quantum machine learning, algorithms with probable performance enhancement over classical protocols typically fall into the category of speeding up basic linear algebra subroutines. The table to the left contains an overview of opportunities for this. An ubiquitous approach used to achieve provable performance enhancement for quantum machine learning here uses the [Harrow-Hassidim-Lloyd](https://en.wikipedia.org/wiki/HHL_algorithm) (HHL) algorithm. \n",
    "\n",
    "The idea here is we are interested in solving a linear system $\\hat{A} \\mathbf{x}=\\mathbf{b}$, where $\\mathbf{x}$ and $\\mathbf{b}$ are $N$-dimensional vectors, and $\\hat{A}$ is an invertible matrix. In this case, given a state $|\\mathbf{b}\\rangle$ and an exponentiated matrix $e^{i \\hat{A}}$ as resources, the HHL process is able to prepare the state\n",
    "\n",
    "$$ |\\mathbf{x} \\rangle =\\hat{A}^{-1} |\\mathbf{b} \\rangle$$\n",
    "\n",
    "in $\\log{N}$ time. Yet, caveats remain. In particular:\n",
    "\n",
    "* The state $\\mathbf{x}$ encodes the information of the classical vector $\\mathbf{x}$ in its amplitudes. Extracting this information into the classical world involves an exponential number of preparations and measurements (quantum tomography).\n",
    "\n",
    "* Preparing the resource state $\\mathbf{b}$ and operator $e^{i \\hat{A}}$ is also not necessarily trivial. Typically, one assumes the ability to hold this kind of information ad-infinitum in a quantum random access memory (QRAM). Yet, this is an oracle which, if existed, would allow classical computers to also solve the linear problem exponentially faster.\n",
    "\n",
    "All-in-all, while new developments are always possible in the horizon, the prospects for provable performance enhancement of machine learning tasks by quantum computers today are uncertain. But that is no reason to give up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd9732",
   "metadata": {},
   "source": [
    "### 1c. Heuristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafe16e3-138c-4ce5-a264-532be63e75eb",
   "metadata": {},
   "source": [
    "Classical machine learning, in general, is founded on methods whose performance are also not typically provable. Such methods are known as heuristics. And as it turns out, quantum heuristics are promising alternatives to classical machine learning in certain scenarios.\n",
    "\n",
    "One such case is when data is born out of quantum experiments. In [Science 376, 6598 (2022)], researchers from Google and collaborators have demonstrated that by studying the classification of randomized quantum dynamics of a quantum processor as symmetric under time-reversal or not (i.e., whether one can differentiate whether a time-dependent behavior is running forward or backward in a movie). Without getting in details, in this work, a standard classical convolutional neural network is trained classically and deployed in tandem with a quantum pre-processing method; this hybrid pipeline is an approach to quantum machine learning. The authors verified that the pre-processing the data with a quantum computer led to a quantum-enhanced method capable of distinguishing the different classes of quantum dynamics. Not only this methodology showcased exponentially less resources for the quantum-enhanced method, it could also be deployed in real experiments with up to 40 qubits.\n",
    "\n",
    "<img src=\"./assets/Google_QML.png\" width=\"500\" height=\"auto\" />\n",
    "\n",
    "So this sets the theme: quantum heuristics can be valuable to analyzing data. In this case, the data was quantum in nature, and the pre-processing of it was done via a quantum computer, making the hybrid workflow inherently a quantum machine learning algorithm. But what kinds of quantum machine learning workflows are possible? That will be the next question we will explore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be102845-9080-42f7-b8b1-361d2a0c2127",
   "metadata": {},
   "source": [
    "#### 1d. Quantum Machine Learning Paradigms: quantum neural networks, Kernel, Reservoir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b499ea-dffd-4cb3-a08e-3dd9ddd171a6",
   "metadata": {},
   "source": [
    "There are multiple ways of approaching quantum machine learning processes and here we will cover three of them. \n",
    "\n",
    "* *Quantum neural networks:* quantum neural networks mimic classical neural networks. Generally speaking, this methodology involves encoding a set of data in a quantum state and then performing operations on that data via a parametrized quantum circuit (that is, one where individual qubit operations are arbitrarily defined by a rotation angle). This parametrized quantum circuit is then trained via variational methods, minimizing a cost function that is designed for a task of interest. While intuitive, this methodology - and many of its more complex variants - faces strong limitations in implementation on real quantum hardware, as well as scaling for large system sizes. These limitations stem from the different types of flat and narrow training landscapes, as well as from the innefficiency of loading classical data inot quantum systems resulting in practical implementations to not scale beyond a few qubits. An important consequence to this is also that the original inspiration on classical machine learning may not transfer so well here: classical neural networks thrive on big data, while quantum neural networks are limited to small data. In fact, this last point is likely to transfer to most methods of quantum machine learning. To learn more about these topics, check Nat. Commun. 12, 6961 (2021), Nature 567, 209 (2019), and Nat. Comput. Sci. 2, 567 (2022).\n",
    "\n",
    "* *Kernel methods:* kernel methods involve transforming the feature space of a data set into an explicit geometric space, and then transforming that space in a way to make tasks such as classification straightforward.\n",
    "\n",
    "<img src=\"./assets/kernel.png\" width=\"500\" height=\"auto\" />\n",
    "\n",
    "In the example above, the data we want to classify in binary categories falls into two mixed clouds of data points and would require a non-linear fit to be separated. That might require too many parameters and also lead to overfitting. Creating a metric space via the dot product of the data, and transforming that via a kernel function $K$ as $\\langle \\boldsymbol{x_i}|\\boldsymbol{x_j}\\rangle \\to K(\\boldsymbol{x_i},\\boldsymbol{x_j})$, we may however spread the the data spatially, not allowing us to draw a simple plane separating the data sets. The quantum version of this process involves utilizing a quantum computer to generate the transformation kernel $K$. There are several ways of doing that; perhaps the most natural is to process the data according to a circuit and then computing the overlap of the analyzed data sets. This is known as the \"fidelity kernel\", which actually is not a very functional idea: computing quantum state overlaps is quantum hard, being akin to performing quantum tomography. Still, other alternative quantum kernel methods exist and generally speaking they tend to be more realistically scalable, avoiding the need for variational training of quantum computer parameters. To learn more about some experiments with quantum kernels, check Mach. Learn. Sci. Technol. 4, 015005 (2023) and PRA 107, 042615 (2023).\n",
    "\n",
    "* *Reservoir methods:* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b7623-00d8-4651-9ca9-0df55d756619",
   "metadata": {},
   "source": [
    "## 2. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d1ab53-2849-4ea5-898f-b6e6b0692d5f",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4982511b-c25f-4ee8-bd63-b20be8d753b6",
   "metadata": {},
   "source": [
    "### 2a. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc72aa8a-7c5d-4ec7-a152-9da4f366e3af",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6168ad2b",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "This marks the end of the third chapter. Congratulations as now you are familiarized with ... \n",
    "Revisiting again our learning objectives, now you are able to\n",
    "- ...\n",
    "\n",
    "This chapter closes the initiate content for QuEra's training on neutral-atom quantum computing. From now, you may branch to specific topics of interest, including solving combinatorial optimization problems, quantum machine learning, simulating more complex quantum dynamics and phases, and much more! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
